{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreWerneck/OS202_ProgrammationParallele/blob/master/TD4_OS202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etdu6cUmeDmX"
      },
      "source": [
        "# Configurer votre colab pour le calcul sur GPU\n",
        "Dans le menu au dessus, choisir le sous-menu **Exécution** puis l'option **Modifier le type d'exécution**. \n",
        "\n",
        "Une fenêtre apparaît où vous pouvez choisir un accélérateur matériel. Choisissez un *GPU* puis *enregistrer* votre choix.\n",
        "\n",
        "Afin de vérifier que vous avez bien configuré votre session pour utiliser un GPU, exécuter le code ci-dessous (en passant la souris, une petite flèche pour l'exécuter apparaît).\n",
        "\n",
        "Si tout se passe bien, un tableau (en ascii) apparaît avec le type de carte (et son architecture) auquel vous avez accès. Si un message d'erreur apparaît, vérifiez dans **Modifier le type d'exécution** que l'accélérateur matériel est bien configuré pour un *GPU*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AisG7sW_bImi",
        "outputId": "af2793c4-c362-41ae-da62-d7d818deae13"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 21 15:31:47 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    30W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKT2rlVxgil3"
      },
      "source": [
        "# Installation de PyCuda\n",
        "\n",
        "Pour utiliser le GPU sous Python il faut soit installer **PyCuda** pour effectuer des calculs, soit **PyTorch** pour effectuer du machine learning accéléré par les GPUs.\n",
        "\n",
        "Dans ce TP, nous nous bornerons uniquement à effectuer des calculs sur GPU !\n",
        "\n",
        "Pour cela, il faut d'abord installer pyCuda et donc exécuter le code ci-dessous (toujours en appuyant sur la flèche pour exécuter le code, et attendez, cela prend un petit moment...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juIs9Ostgkoc",
        "outputId": "049a057c-d200-4bf8-88a7-ef423c1cfdc6"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.8/dist-packages (2022.2.2)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.8/dist-packages (from pycuda) (1.2.4)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.8/dist-packages (from pycuda) (2022.1.14)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2011.2->pycuda) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from mako->pycuda) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qudDlvJtlFvM"
      },
      "source": [
        "# Vérification du bon fonctionnement du module PyCuda\n",
        "\n",
        "Afin de vérifier le bon fonctionnement de l'installation, nous allons écrire un script Cuda qui servira en même temps d'exemple pour le TP d'aujourd'hui. Ce script sera scindé en plusieurs morceaux et commenté pour que vous compreniez chaque partie du code.\n",
        "\n",
        "Ce code sera très simple : on va créer une matrice 4x4 avec des données prises \"au hasard\" (mais avec une graine aléatoire fixée, donc...) , recopier ce tableau dans la mémoire de la carte graphique et demander à la carte graphique de doubler la valeur de chaque élément de la matrice puis de recopier dans la mémoire de l'ordinateur les valeurs calculées. On affiche ensuite la matrice initiale et la matrice transformée.\n",
        "\n",
        "Dans un premier temps, chargeons les modules python nécessaire à l'exécution d'un noyau Cuda (**Remarque** : l'importation de ces modules n'est nécessaire qu'une seule fois pour **TOUTE** la session. Il sera donc inutile de reimporter ces modules dans le reste du TD !) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqWKO6k_mw45"
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDlqPZFGm1mH"
      },
      "source": [
        "Créons à l'aide de numpy un tableau *a* dont les valeurs aléatoires sont issues d'une graine fixée :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHjGxA72nD5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8baabf-c512-485e-c72a-d2b9e0e2e190"
      },
      "source": [
        "import numpy\n",
        "numpy.random.seed(1729)\n",
        "a = numpy.random.randn(4,4) # Sous forme de matrice 4 x 4\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.68733944, -0.82099471,  1.65236086, -0.57529304],\n",
              "       [ 1.09896774,  0.92594603, -0.99341379, -0.85822114],\n",
              "       [ 0.07488676,  0.52935554,  0.12095155, -0.22442361],\n",
              "       [-1.55667849,  0.05594088,  0.16147154, -2.13464176]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB_UhGnJnL0H"
      },
      "source": [
        "Puisque certaines cartes graphiques supportent mal le double précision, nous allons demander à Python que les éléments de *a* soient en simple précision :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN3tt27lnZYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950016a8-2672-46fe-c731-a95012723af8"
      },
      "source": [
        "a = a.astype(numpy.float32)\n",
        "print(a.nbytes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFvuQK_wnccf"
      },
      "source": [
        "Nous allons ensuite allouer de la place mémoire sur la mémoire vive du GPU. Comme en C, la place mémoire est exprimée en *Octets* :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WXc0_Q8nqw3"
      },
      "source": [
        "a_gpu = cuda.mem_alloc(a.nbytes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqIHO5oYnugQ"
      },
      "source": [
        "Une fois la réservation sur le GPU de faite, on recopie les valeurs de *a* dans le tableau *a_gpu* que l'on vient de réserver (htod signifie host **to** device):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMiVGjKEoAJJ"
      },
      "source": [
        "cuda.memcpy_htod(a_gpu, a) # from a to a_gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2EIIhLwoDLY"
      },
      "source": [
        "Il faut ensuite écrire le noyau qui s'exécutera sur la carte graphique à l'aide du langage CUDA (qui est une extension du langage C).\n",
        "\n",
        "**Remarquez** dans le code qu'on s'assure que les indices donnés par les numéros de threads ne dépassent pas la dimension de la matrice !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_uaN7JNok9-"
      },
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "__global__ void doublify( int dim_x, int dim_y, float *a )\n",
        "{\n",
        "  if ((threadIdx.x < dim_x) && (threadIdx.y < dim_y))\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y * dim_x;\n",
        "    a[idx] *= 2;\n",
        "  }\n",
        "}\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqsGbd-LqAlF"
      },
      "source": [
        "Nous allons récupérer ensuite un \"handle\" sur le noyau cuda que l'on vient de créer (en invoquant le nom de la fonction) et l'invoquer sur la carte graphique en dimensionnant la grille de calcul à l'aide de *block=(4,4,1)* (et en l'adaptant aux dimensions de la matrice).\n",
        "\n",
        "Ici, nous n'avons pas besoin de configurer de grilles car la dimension de la matrice *a* est petite, mais comme la taille d'un bloc dans une direction est limitée à 256, pour des cas plus gros, il faudra également passer une grille en paramètre à l'aide de *grid=(x,y,z)* où *x,y* et *z* sont des valeurs entières positives et utiliser dans le noyau cuda les valeurs *x,y* et *z* de **blockIdx** et **blockDim**.\n",
        "\n",
        "**REMARQUE IMPORTANTE** : Le noyau cuda ne veut que des types C basiques en argument. Or un entier python est tout sauf un type basique du C. Donc pour passer un argument entier à un noyau cuda, il faut créer un entier 32 bits à l'aide de numpy.int32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW9-l0XaqSuH"
      },
      "source": [
        "func = mod.get_function(\"doublify\")\n",
        "dim = numpy.int32(4)\n",
        "func(dim, dim, a_gpu, block=(4,4,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbE0Dg-7qRlt"
      },
      "source": [
        "Il ne reste plus qu'à récupérer les nouvelles valeurs de la matrice en transférant les données de la matrice contenue par le GPU dans un tableau numpy se trouvant dans la RAM de l'ordinateur (dtoh signifie device **to** host) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt77Pr7JqrPU"
      },
      "source": [
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCEHT9OMwLCl"
      },
      "source": [
        "Il ne reste plus qu'à afficher la matrice initiale puis la matrice obtenue par le calcul sur GPU :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7-qzHVFwP9R",
        "outputId": "e70291c3-4a6e-4209-cba4-209c0735bb9f"
      },
      "source": [
        "print(f\"a : {a}\")\n",
        "print(f\"a_gpu : {a_doubled}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a : [[-0.6873394  -0.82099473  1.6523609  -0.57529306]\n",
            " [ 1.0989678   0.92594606 -0.9934138  -0.8582211 ]\n",
            " [ 0.07488676  0.5293555   0.12095155 -0.22442362]\n",
            " [-1.5566785   0.05594088  0.16147153 -2.1346416 ]]\n",
            "a_gpu : [[-1.3746789  -1.6419895   3.3047218  -1.1505861 ]\n",
            " [ 2.1979356   1.8518921  -1.9868276  -1.7164422 ]\n",
            " [ 0.14977352  1.058711    0.2419031  -0.44884723]\n",
            " [-3.113357    0.11188176  0.32294306 -4.2692833 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEHbBbLwxwg"
      },
      "source": [
        "## Exercices de mises en bouche\n",
        "\n",
        "En vous inspirant du programme commenté ci-dessus, écrivez un code avec un noyau Cuda qui fait la somme de deux vecteurs de réels simples précisions et qui range le résultat dans un troisième vecteur. \n",
        "\n",
        "On s'exercera à utiliser des vecteurs de \"grandes\" dimensions (> 256) afin de s'entrainer à calculer des indices globaux dans le noyau cuda à l'aide de *threadIdx.x*, *blockIdx.x* et *dimBlock.x*.\n",
        "\n",
        "Ecrivez (ou copier coller) votre code dans la cellule ci-dessous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdP6BpWQyDyx"
      },
      "source": [
        "numpy.random.seed(0)\n",
        "N = 300\n",
        "v_source0 = numpy.random.randn(N)\n",
        "v_source1 = numpy.random.randn(N)\n",
        "v_result = numpy.zeros(N)\n",
        "\n",
        "v_source0 = v_source0.astype(numpy.float32)\n",
        "v_source1 = v_source1.astype(numpy.float32)\n",
        "v_result = numpy.empty_like(v_source0)\n",
        "\n",
        "v_source0_gpu = cuda.mem_alloc(v_source0.nbytes)\n",
        "v_source1_gpu = cuda.mem_alloc(v_source1.nbytes)\n",
        "v_result_gpu = cuda.mem_alloc(v_result.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(v_source0_gpu,v_source0)\n",
        "cuda.memcpy_htod(v_source1_gpu,v_source1)\n",
        "cuda.memcpy_htod(v_result_gpu,v_result)\n",
        "\n",
        "# v_source1.nbytes/(512*512)*8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = SourceModule(\"\"\"\n",
        "__global__ void deviceSum( int N, float *s0, float *s1 ,float *a)\n",
        "{\n",
        "  int idx = blockDim.x * blockIdx.x + threadIdx.x; \n",
        "  if (idx < N)\n",
        "  {\n",
        "    a[idx] = s0[idx] + s1[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "UlJ5CG4SadfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math as m\n",
        "blocksize = 256\n",
        "gridsize = m.ceil(float(N)/blocksize)\n",
        "gridDim   = (gridsize, 1, 1)\n",
        "blockDim = (blocksize,1,1)"
      ],
      "metadata": {
        "id": "UpIqJl79XSU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func = f.get_function(\"deviceSum\")\n",
        "dim = numpy.int32(N)\n",
        "func(dim,v_source0_gpu, v_source1_gpu,v_result_gpu,block=blockDim,grid=gridDim)\n",
        "a_summed = numpy.empty_like(v_result)\n",
        "cuda.memcpy_dtoh(a_summed, v_result_gpu)\n",
        "print(f\"v_source0 : {v_source0}\")\n",
        "print(f\"v_source1 : {v_source1}\")\n",
        "print(f\"v_result_gpu : {a_summed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEvHhZXboH4y",
        "outputId": "314ceb37-ad72-4913-82de-6561866de45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v_source0 : [ 1.7640524   0.4001572   0.978738    2.2408931   1.867558   -0.9772779\n",
            "  0.95008844 -0.1513572  -0.10321885  0.41059852  0.14404356  1.4542735\n",
            "  0.7610377   0.12167501  0.44386324  0.33367434  1.4940791  -0.20515826\n",
            "  0.3130677  -0.85409576 -2.5529897   0.6536186   0.8644362  -0.742165\n",
            "  2.2697546  -1.4543657   0.04575852 -0.18718386  1.5327792   1.4693588\n",
            "  0.15494743  0.37816253 -0.88778573 -1.9807965  -0.34791216  0.15634897\n",
            "  1.2302907   1.2023798  -0.3873268  -0.30230275 -1.048553   -1.420018\n",
            " -1.7062702   1.9507754  -0.5096522  -0.4380743  -1.2527953   0.7774904\n",
            " -1.6138978  -0.21274029 -0.89546657  0.3869025  -0.51080513 -1.1806322\n",
            " -0.02818223  0.42833188  0.06651722  0.3024719  -0.6343221  -0.36274117\n",
            " -0.67246044 -0.35955316 -0.8131463  -1.7262826   0.17742614 -0.40178093\n",
            " -1.6301984   0.46278226 -0.9072984   0.0519454   0.7290906   0.12898292\n",
            "  1.1394007  -1.2348258   0.40234163 -0.6848101  -0.87079716 -0.5788497\n",
            " -0.31155252  0.05616534 -1.1651498   0.9008265   0.46566245 -1.5362437\n",
            "  1.4882522   1.8958892   1.1787796  -0.17992483 -1.0707526   1.0544517\n",
            " -0.40317693  1.222445    0.20827498  0.97663903  0.3563664   0.7065732\n",
            "  0.01050002  1.7858706   0.12691209  0.40198937  1.8831507  -1.347759\n",
            " -1.270485    0.9693967  -1.1731234   1.9436212  -0.41361898 -0.7474548\n",
            "  1.922942    1.4805148   1.867559    0.90604466 -0.86122566  1.9100649\n",
            " -0.26800337  0.8024564   0.947252   -0.15501009  0.61407936  0.9222067\n",
            "  0.37642553 -1.0994008   0.2982382   1.3263859  -0.69456786 -0.14963454\n",
            " -0.43515354  1.8492638   0.67229474  0.40746182 -0.76991606  0.5392492\n",
            " -0.6743327   0.03183056 -0.6358461   0.67643327  0.57659084 -0.20829876\n",
            "  0.3960067  -1.0930616  -1.4912575   0.4393917   0.1666735   0.63503146\n",
            "  2.3831449   0.94447947 -0.91282225  1.1170163  -1.3159074  -0.4615846\n",
            " -0.0682416   1.7133427  -0.74475485 -0.82643855 -0.09845252 -0.6634783\n",
            "  1.1266359  -1.0799315  -1.1474687  -0.43782005 -0.49803245  1.929532\n",
            "  0.9494208   0.08755124 -1.2254355   0.844363   -1.0002153  -1.5447711\n",
            "  1.1880298   0.3169426   0.9208588   0.31872764  0.8568306  -0.6510256\n",
            " -1.0342429   0.6815945  -0.80340964 -0.6895498  -0.4555325   0.01747916\n",
            " -0.35399392 -1.3749512  -0.6436184  -2.2234032   0.62523144 -1.6020577\n",
            " -1.1043833   0.05216508 -0.739563    1.5430146  -1.2928569   0.26705086\n",
            " -0.03928282 -1.1680934   0.5232767  -0.17154633  0.77179056  0.82350415\n",
            "  2.163236    1.336528   -0.36918184 -0.23937918  1.0996596   0.6552637\n",
            "  0.64013153 -1.616956   -0.02432613 -0.7380309   0.2799246  -0.09815039\n",
            "  0.9101789   0.3172182   0.78632796 -0.4664191  -0.94444627 -0.4100497\n",
            " -0.01702041  0.37915173  2.259309   -0.04225715 -0.955945   -0.34598178\n",
            " -0.463596    0.48148146 -1.540797    0.06326199  0.15650654  0.23218104\n",
            " -0.5973161  -0.23792173 -1.424061   -0.49331987 -0.54286146  0.41605005\n",
            " -1.1561824   0.7811981   1.4944845  -2.069985    0.42625874  0.676908\n",
            " -0.63743705 -0.3972718  -0.13288058 -0.29779088 -0.30901298 -1.6760038\n",
            "  1.1523316   1.0796186  -0.81336427 -1.4664243   0.5210649  -0.57578796\n",
            "  0.14195317 -0.31932843  0.69153875  0.6947491  -0.7255974  -1.383364\n",
            " -1.5829384   0.6103794  -1.1888592  -0.5068163  -0.596314   -0.0525673\n",
            " -1.9362798   0.1887786   0.52389103  0.08842209 -0.31088617  0.09740017\n",
            "  0.39904633 -2.7725928   1.9559124   0.39009333 -0.6524086  -0.39095336\n",
            "  0.49374178 -0.11610394 -2.0306845   2.064493   -0.11054066  1.0201727\n",
            " -0.69204986  1.5363771   0.2863437   0.60884386 -1.0452534   1.2111453\n",
            "  0.68981814  1.3018463  -0.6280876  -0.48102713  2.3039167  -1.0600158\n",
            " -0.1359497   1.1368914   0.09772497  0.5829537  -0.39944902  0.37005588]\n",
            "v_source1 : [-1.3065269   1.6581306  -0.11816405 -0.6801782   0.6663831  -0.4607198\n",
            " -1.3342584  -1.3467175   0.69377315 -0.15957344 -0.13370156  1.0777438\n",
            " -1.1268258  -0.7306777  -0.3848798   0.09435159 -0.04217145 -0.2868872\n",
            " -0.0616264  -0.10730527 -0.7196044  -0.812993    0.27451634 -0.8909151\n",
            " -1.1573553  -0.31229225 -0.15766701  2.2567234  -0.7047003   0.9432607\n",
            "  0.7471883  -1.1889449   0.77325296 -1.1838807  -2.6591723   0.60631955\n",
            " -1.7558906   0.45093447 -0.6840109   1.6595508   1.0685093  -0.4533858\n",
            " -0.6878376  -1.2140774  -0.44092262 -0.28035548 -0.36469355  0.15670386\n",
            "  0.5785215   0.34965447 -0.76414394 -1.4377915   1.3645319  -0.6894492\n",
            " -0.6522936  -0.52118933 -1.8430696  -0.477974   -0.4796558   0.6203583\n",
            "  0.6984571   0.00377089  0.93184835  0.339965   -0.01568211  0.16092817\n",
            " -0.19065349 -0.3948495  -0.26773354 -1.1280113   0.2804417  -0.9931236\n",
            "  0.8416313  -0.24945858  0.04949498  0.4938368   0.6433145  -1.5706234\n",
            " -0.20690368  0.8801789  -1.6981058   0.38728046 -2.2555642  -1.0225068\n",
            "  0.03863055 -1.6567152  -0.98551077 -1.471835    1.648135    0.16422775\n",
            "  0.5672903  -0.2226751  -0.35343176 -1.6164742  -0.29183736 -0.7614922\n",
            "  0.8579239   1.1411018   1.4665787   0.85255194 -0.5986539  -1.1158969\n",
            "  0.7666632   0.3562928  -1.7685385   0.3554818   0.8145198   0.05892559\n",
            " -0.18505368 -0.8076485  -1.4465348   0.800298   -0.30911446 -0.23346666\n",
            "  1.7327212   0.6845011   0.370825    0.1420618   1.5199949   1.7195894\n",
            "  0.9295051   0.5822246  -2.094603    0.12372191 -0.13010696  0.09395323\n",
            "  0.9430461  -2.7396772  -0.56931204  0.26990435 -0.46684554 -1.4169061\n",
            "  0.8689635   0.27687192 -0.97110456  0.3148172   0.8215857   0.00529265\n",
            "  0.8005648   0.07826018 -0.39522898 -1.1594205  -0.08593076  0.19429293\n",
            "  0.87583274 -0.11510747  0.4574156  -0.964612   -0.78262913 -0.1103893\n",
            " -1.0546285   0.8202478   0.46313033  0.27909577  0.3389041   2.0210435\n",
            " -0.4688642  -2.2014413   0.1993002  -0.05060354 -0.51751906 -0.97882986\n",
            " -0.43918952  0.18133843 -0.5028167   2.4124537  -0.96050435 -0.79311734\n",
            " -2.28862     0.25148442 -2.0164065  -0.53945464 -0.27567053 -0.70972794\n",
            "  1.7388726   0.99439436  1.3191369  -0.8824188   1.128594    0.49600095\n",
            "  0.77140594  1.0294389  -0.90876323 -0.42431763  0.86259604 -2.6556191\n",
            "  1.5133281   0.55313206 -0.04570396  0.22050765 -1.0299352  -0.34994337\n",
            "  1.1002843   1.298022    2.696224   -0.07392467 -0.65855294 -0.51423395\n",
            " -1.0180418  -0.07785475  0.38273242 -0.03424228  1.0963469  -0.2342158\n",
            " -0.34745064 -0.5812685  -1.6326345  -1.5677677  -1.179158    1.3014281\n",
            "  0.8952603   1.3749641  -1.3322116  -1.9686247  -0.6600563   0.17581895\n",
            "  0.49869028  1.0479722   0.28427967  1.7426687  -0.22260568 -0.9130792\n",
            " -1.6812183  -0.8889713   0.24211796 -0.8887203   0.9367425   1.4123276\n",
            " -2.369587    0.8640523  -2.239604    0.40149906  1.2248706   0.0648561\n",
            " -1.2796892  -0.5854312  -0.26164544 -0.18224478 -0.20289683 -0.10988278\n",
            "  0.21348006 -1.2085737  -0.24201983  1.5182612  -0.38464543 -0.4438361\n",
            "  1.0781974  -2.5591846   1.1813786  -0.63190377  0.16392857  0.09632136\n",
            "  0.9424681  -0.26759475 -0.6780258   1.2978458  -2.364174    0.02033418\n",
            " -1.3479254  -0.7615734   2.0112567  -0.04459543  0.1950697  -1.7815628\n",
            " -0.7290447   0.1965574   0.3547577   0.61688656  0.0086279   0.5270042\n",
            "  0.4537819  -1.8297404   0.03700572  0.76790243  0.5898798  -0.36385882\n",
            " -0.8056265  -1.1183119  -0.13105401  1.1330799  -1.9518042  -0.6598917\n",
            " -1.1398025   0.7849575  -0.5543096  -0.47063765 -0.21694957  0.44539326\n",
            " -0.392389   -3.046143    0.5433119   0.43904296 -0.21954103 -1.0840366\n",
            "  0.35178012  0.37923554 -0.47003287 -0.21673147 -0.9301565  -0.17858909]\n",
            "v_result_gpu : [ 0.4575255   2.0582879   0.86057395  1.560715    2.533941   -1.4379977\n",
            " -0.38417    -1.4980747   0.5905543   0.25102508  0.010342    2.5320172\n",
            " -0.3657881  -0.6090027   0.05898345  0.42802593  1.4519076  -0.49204546\n",
            "  0.2514413  -0.96140105 -3.272594   -0.15937442  1.1389525  -1.6330801\n",
            "  1.1123993  -1.766658   -0.1119085   2.0695395   0.8280789   2.4126196\n",
            "  0.9021357  -0.81078243 -0.11453277 -3.1646771  -3.0070844   0.7626685\n",
            " -0.52559996  1.6533144  -1.0713377   1.3572481   0.01995635 -1.8734038\n",
            " -2.3941078   0.73669803 -0.9505748  -0.7184298  -1.6174889   0.9341942\n",
            " -1.0353763   0.13691418 -1.6596105  -1.050889    0.85372674 -1.8700814\n",
            " -0.68047583 -0.09285745 -1.7765523  -0.17550209 -1.1139779   0.25761712\n",
            "  0.02599669 -0.35578227  0.11870205 -1.3863176   0.16174403 -0.24085276\n",
            " -1.8208518   0.06793275 -1.1750319  -1.0760659   1.0095322  -0.8641407\n",
            "  1.981032   -1.4842844   0.45183662 -0.19097331 -0.22748268 -2.1494732\n",
            " -0.5184562   0.93634427 -2.8632555   1.2881069  -1.7899017  -2.5587506\n",
            "  1.5268828   0.23917401  0.19326884 -1.6517599   0.5773823   1.2186794\n",
            "  0.16411337  0.9997699  -0.14515679 -0.6398351   0.06452903 -0.054919\n",
            "  0.86842394  2.9269724   1.5934908   1.2545413   1.2844968  -2.463656\n",
            " -0.50382185  1.3256896  -2.9416618   2.299103    0.40090084 -0.68852925\n",
            "  1.7378883   0.6728663   0.4210242   1.7063427  -1.1703401   1.6765983\n",
            "  1.4647179   1.4869576   1.318077   -0.01294829  2.1340742   2.641796\n",
            "  1.3059306  -0.51717615 -1.7963649   1.4501078  -0.82467484 -0.05568131\n",
            "  0.50789255 -0.8904134   0.1029827   0.67736614 -1.2367616  -0.87765694\n",
            "  0.1946308   0.30870247 -1.6069506   0.99125046  1.3981766  -0.20300612\n",
            "  1.1965716  -1.0148014  -1.8864865  -0.72002876  0.08074273  0.82932436\n",
            "  3.2589777   0.829372   -0.45540664  0.15240431 -2.0985365  -0.5719739\n",
            " -1.1228701   2.5335906  -0.28162453 -0.5473428   0.24045159  1.3575652\n",
            "  0.6577717  -3.2813728  -0.9481685  -0.4884236  -1.0155516   0.9507022\n",
            "  0.51023126  0.26888967 -1.7282522   3.2568166  -1.9607196  -2.3378885\n",
            " -1.1005902   0.568427   -1.0955477  -0.220727    0.58116007 -1.3607535\n",
            "  0.7046298   1.6759889   0.5157272  -1.5719686   0.67306155  0.5134801\n",
            "  0.417412   -0.3455124  -1.5523816  -2.6477208   1.4878275  -4.257677\n",
            "  0.40894473  0.60529715 -0.78526694  1.7635223  -2.322792   -0.08289251\n",
            "  1.0610015   0.12992859  3.2195005  -0.245471    0.11323762  0.3092702\n",
            "  1.145194    1.2586732   0.01355058 -0.27362147  2.1960063   0.42104793\n",
            "  0.2926809  -2.1982245  -1.6569606  -2.3057985  -0.89923334  1.2032777\n",
            "  1.8054392   1.6921823  -0.54588366 -2.4350438  -1.6045026  -0.23423076\n",
            "  0.48166987  1.4271239   2.5435886   1.7004116  -1.1785507  -1.259061\n",
            " -2.1448143  -0.40748987 -1.298679   -0.8254583   1.0932491   1.6445087\n",
            " -2.966903    0.6261306  -3.6636648  -0.09182081  0.6820091   0.48090616\n",
            " -2.4358716   0.19576687  1.2328391  -2.2522297   0.22336191  0.56702524\n",
            " -0.423957   -1.6058455  -0.3749004   1.2204703  -0.6936584  -2.11984\n",
            "  2.2305288  -1.479566    0.36801434 -2.098328    0.68499345 -0.47946662\n",
            "  1.0844213  -0.5869232   0.01351297  1.992595   -3.0897713  -1.3630298\n",
            " -2.9308639  -0.15119398  0.8223975  -0.55141175 -0.4012443  -1.83413\n",
            " -2.6653244   0.38533598  0.87864876  0.7053087  -0.30225828  0.6244044\n",
            "  0.85282826 -4.602333    1.992918    1.1579957  -0.06252879 -0.7548122\n",
            " -0.31188473 -1.2344158  -2.1617384   3.1975727  -2.0623448   0.360281\n",
            " -1.8318523   2.3213346  -0.2679659   0.13820621 -1.262203    1.6565385\n",
            "  0.29742914 -1.7442968  -0.08477569 -0.04198417  2.0843756  -2.1440525\n",
            "  0.21583042  1.5161269  -0.3723079   0.3662222  -1.3296056   0.1914668 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esWwXhGMy8vJ"
      },
      "source": [
        "Une fois le code mis au point, recopiez le ci-dessous et adaptez le pour additionner deux matrices carrées dans une troisième."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMAqLHVmzJbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b2680b-a704-4d73-9048-01342ca7c484"
      },
      "source": [
        "numpy.random.seed(0)\n",
        "M = 30\n",
        "v_matrix0 = numpy.random.randn(M,M)\n",
        "v_matrix1 = numpy.random.randn(M,M)\n",
        "v_matrix_r = numpy.empty_like(v_matrix0)\n",
        "\n",
        "v_matrix0 = v_matrix0.astype(numpy.float32)\n",
        "v_matrix1 = v_matrix1.astype(numpy.float32)\n",
        "v_matrix_r = v_matrix_r.astype(numpy.float32)\n",
        "\n",
        "v_matrix0_gpu = cuda.mem_alloc(v_matrix0.nbytes)\n",
        "v_matrix1_gpu = cuda.mem_alloc(v_matrix1.nbytes)\n",
        "v_matrix_r_gpu = cuda.mem_alloc(v_matrix_r.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(v_matrix0_gpu,v_matrix0)\n",
        "cuda.memcpy_htod(v_matrix1_gpu,v_matrix1)\n",
        "cuda.memcpy_htod(v_matrix_r_gpu,v_matrix_r)\n",
        "\n",
        "# v_source1.nbytes/(512*512)*8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = SourceModule(\"\"\"\n",
        "__global__ void deviceMatrixSum(int width, float *s0, float *s1 ,float *a)\n",
        "{\n",
        "  int idx_col = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int idx_row = blockDim.y * blockIdx.y + threadIdx.y; \n",
        "  if ((idx_row < width) && (idx_col < width))\n",
        "  {\n",
        "    int element_idx = idx_row * width + idx_col;\n",
        "    a[element_idx] = s0[element_idx] + s1[element_idx]; \n",
        "  }\n",
        "}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "0l-ytlP5e2jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blocksize = 256\n",
        "gridsize = m.ceil(float(N)/blocksize)\n",
        "gridDim   = (gridsize, 1, 1)\n",
        "blockDim = (blocksize,1,1)"
      ],
      "metadata": {
        "id": "eygHfF6MlJ-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func = f.get_function(\"deviceMatrixSum\")\n",
        "dim_x = numpy.int32(M)\n",
        "dim_y = numpy.int32(M)\n",
        "func(dim_x,v_matrix0_gpu, v_matrix1_gpu,v_matrix_r_gpu,block=blockDim,grid=gridDim)\n",
        "m_summed = numpy.empty_like(v_matrix_r)\n",
        "cuda.memcpy_dtoh(m_summed, v_matrix_r_gpu)\n",
        "# print(f\"v_matrix0 : {v_matrix0}\")\n",
        "# print(f\"v_matrix1 : {v_matrix1}\")\n",
        "print(f\"v_matrix_r_gpu : {m_summed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rALQAQ6-fiM0",
        "outputId": "bf758074-5166-4359-b034-cca661c45896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v_matrix_r_gpu : [[ 3.02319646e-01 -2.83282578e-01  1.34628296e+00  2.43120480e+00\n",
            "   1.01582885e+00  8.45445752e-01  4.28508759e-01 -1.33604372e+00\n",
            "   8.57474566e-01  1.73966134e+00 -6.73449516e-01  5.29261827e-02\n",
            "   1.79147601e+00 -1.92564869e+00 -7.82758355e-01  1.30112052e+00\n",
            "   1.43872654e+00 -4.69095618e-01  6.65884316e-01 -1.00687015e+00\n",
            "  -3.85167646e+00  1.92969394e+00  2.18945026e+00 -5.36832452e-01\n",
            "   2.31488872e+00  8.85259151e-01 -2.30674326e-01 -4.46760833e-01\n",
            "   1.89726043e+00  2.94068074e+00]\n",
            " [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00 -2.52588033e-12\n",
            "   0.00000000e+00  0.00000000e+00 -2.52588033e-12  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  2.50587776e-34  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -3.47522019e-43  0.00000000e+00  0.00000000e+00 -3.47522019e-43\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  1.60608543e+10\n",
            "   0.00000000e+00  0.00000000e+00  1.60608543e+10  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  1.60219008e-27  0.00000000e+00\n",
            "   0.00000000e+00  1.60219008e-27  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  1.31004615e+23\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   1.31004615e+23  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "  -2.42102914e-27  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "  -5.18008584e+17  0.00000000e+00  0.00000000e+00 -5.18008584e+17\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -2.44833983e-26  0.00000000e+00  0.00000000e+00 -2.44833983e-26\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  1.91874665e+34  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "   1.91874665e+34  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   2.92472053e+15  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00  2.92472053e+15\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   1.01304840e-29  0.00000000e+00  0.00000000e+00  1.01304840e-29\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00]\n",
            " [ 0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00            -inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "              inf  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00             inf  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  0.00000000e+00  0.00000000e+00             inf\n",
            "   0.00000000e+00  0.00000000e+00             inf  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00]\n",
            " [ 0.00000000e+00            -inf  0.00000000e+00  0.00000000e+00\n",
            "             -inf  0.00000000e+00  0.00000000e+00            -inf\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_67yypc0yL0g"
      },
      "source": [
        "# Exercice final\n",
        "\n",
        "Nous allons de nouveau nous intéresser à l'ensemble de Mandelbrot. La cellule ci-dessous contient un code permettant de calculer à l'aide de numpy un ensemble de mandelbrot (le code est simplifié par rapport aux codes sur CPU pour faciliter le TP même si il utilise la notation vectorielle de numpy (il faudra y faire attention pour code le noyau cuda !) : code repris de https://stackoverflow.com/questions/60467316/displaying-mandelbrot-set-in-python-using-matplotlib-pyplot-and-numpy).\n",
        "\n",
        "Transformez le de sorte que sur GPU, chaque thread calcule un pixel de l'image de destination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "YcAhzA4Gzb51",
        "outputId": "adb80f6c-9468-419e-8559-6a496ed9e055"
      },
      "source": [
        "import pylab as plt\n",
        "import numpy as np\n",
        "# initial values \n",
        "loop = 100 # number of interations\n",
        "div = 1000 # divisions\n",
        "# all possible values of c\n",
        "c = np.linspace(-2,2,div)[:,np.newaxis] + 1j*np.linspace(-1.5,1.5,div)[np.newaxis,:]\n",
        "# array of ones of same dimensions as c\n",
        "ones = np.ones(np.shape(c), np.int)\n",
        "# Array that will hold colors for plot, initial value set here will be\n",
        "# the color of the points in the mandelbrot set, i.e. where the series\n",
        "# converges.\n",
        "# For the code below to work, this initial value must at least be 'loop'.\n",
        "# Here it is loop + 5\n",
        "color = ones * loop + 5\n",
        "z = 0\n",
        "for n in range(0,loop):\n",
        "      z = z**2 + c\n",
        "      diverged = np.abs(z)>2\n",
        "      # Store value of n at which series was detected to diverge.\n",
        "      # The later the series is detected to diverge, the higher\n",
        "      # the 'color' value.\n",
        "      color[diverged] = np.minimum(color[diverged], ones[diverged]*n)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [12, 7.5]\n",
        "# contour plot with real and imaginary parts of c as axes\n",
        "# and colored according to 'color'\n",
        "plt.contourf(c.real, c.imag, color)\n",
        "plt.xlabel(\"Real($c$)\")\n",
        "plt.ylabel(\"Imag($c$)\")\n",
        "plt.xlim(-2,2)\n",
        "plt.ylim(-1.5,1.5)\n",
        "plt.savefig(\"plot.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in square\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in square\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in absolute\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x540 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}